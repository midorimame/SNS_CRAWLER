import os
import re
import logging
from typing import Dict, List, Optional

import requests
from dotenv import load_dotenv
from pathlib import Path
import json

load_dotenv('/home/pmi/venvs/source_code/.env')
USERNAME = os.getenv("IG_USERNAME")
PASSWORD = os.getenv("IG_PASSWORD")
INSTAGRAM_BUSINESS_ID = os.getenv("INSTAGRAM_BUSINESS_ID")
ACCESS_TOKEN = os.getenv("ACCESS_TOKEN")

# íŒŒì¼ ê²½ë¡œ (í˜„ì¬ íŒŒì¼ ìœ„ì¹˜ ê¸°ì¤€)
BASE_DIR = Path(__file__).parent
COOKIE_PATH = BASE_DIR / "instagram_cookies.pkl"
DATA_FILE = BASE_DIR / "instagram_media.json"


def normalize_permalink(url: Optional[str]) -> Optional[str]:
    """
    permalinkë¥¼ ì •ê·œí™”í•˜ì—¬ shortcodeë§Œ ì¶”ì¶œ
    - instagram_media.json í˜•ì‹: "https://www.instagram.com/reel/DQ5hGrqE6SP/"
    - ìˆ˜ì§‘í•œ í˜•ì‹: "https://www.instagram.com/pmi_min/reel/DD4hDgTy82T/"
    â†’ ë‘˜ ë‹¤ shortcodeë§Œ ì¶”ì¶œí•˜ì—¬ ë¹„êµ: "DQ5hGrqE6SP", "DD4hDgTy82T"
    """
    if not url:
        return None
    # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì œê±°
    url = url.split("?")[0]
    # ëì— ìŠ¬ë˜ì‹œ ì œê±°
    url = url.rstrip("/")
    
    # shortcode ì¶”ì¶œ
    # í˜•ì‹ 1: /reel/SHORTCODE ë˜ëŠ” /p/SHORTCODE
    # í˜•ì‹ 2: /USERNAME/reel/SHORTCODE ë˜ëŠ” /USERNAME/p/SHORTCODE
    if "/reel/" in url:
        parts = url.split("/reel/")
        if len(parts) > 1:
            shortcode = parts[-1].split("/")[0].split("?")[0]
            return shortcode
    elif "/p/" in url:
        parts = url.split("/p/")
        if len(parts) > 1:
            shortcode = parts[-1].split("/")[0].split("?")[0]
            return shortcode
    
    return None


def setup_logging(log_file: str = "instagram.log") -> None:
    """ë¡œê¹… ì„¤ì •: íŒŒì¼ê³¼ ì½˜ì†” ëª¨ë‘ì— ë¡œê·¸ ì¶œë ¥"""
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    
    # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±° (ì¤‘ë³µ ë°©ì§€)
    logger.handlers.clear()
    
    # ë¡œê·¸ í¬ë§· ì„¤ì •
    formatter = logging.Formatter(
        '%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬ (ì¶”ê°€ ëª¨ë“œë¡œ ê¸°ì¡´ ë¡œê·¸ ë³´ì¡´)
    file_handler = logging.FileHandler(log_file, encoding='utf-8', mode='a')
    file_handler.setLevel(logging.INFO)
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    logging.info(f"ë¡œê¹…ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ë¡œê·¸ íŒŒì¼: {log_file}")


def load_existing_data() -> tuple[Dict[str, Dict[str, dict]], Dict[str, dict]]:
    """
    ê¸°ì¡´ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  permalink ê¸°ì¤€ ì¸ë±ìŠ¤ë„ ìƒì„±
    
    Returns:
        (hashtag_media_data, permalink_index)
        - hashtag_media_data: {hashtag: {media_id: item}}
        - permalink_index: {shortcode: item} (permalink ê¸°ì¤€ ì¸ë±ìŠ¤)
    """
    if not DATA_FILE.exists():
        return {}, {}

    with open(DATA_FILE, "r", encoding="utf-8") as file:
        try:
            raw_data = json.load(file)
        except json.JSONDecodeError:
            logging.warning("ê¸°ì¡´ JSON íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
            return {}, {}

    data: Dict[str, Dict[str, dict]] = {}
    permalink_index: Dict[str, dict] = {}  # {shortcode: item}

    if isinstance(raw_data, list):
        for item in raw_data:
            if not isinstance(item, dict):
                continue
            hashtag = item.get("hashtag")
            media_id = item.get("id")
            # idëŠ” í•„ìˆ˜, hashtagëŠ” ì—†ìœ¼ë©´ "unknown"ìœ¼ë¡œ ì²˜ë¦¬
            if not media_id:
                continue
            # hashtagê°€ ì—†ìœ¼ë©´ "unknown" ì‚¬ìš© (ê¸°ì¡´ ë°ì´í„° ë³´ì¡´)
            # ì›ë³¸ hashtag ê°’ì€ í•­ëª©ì— ê·¸ëŒ€ë¡œ ìœ ì§€ë¨ (None ë˜ëŠ” ì—†ìŒ)
            storage_hashtag = hashtag if hashtag else "unknown"
            data.setdefault(storage_hashtag, {})[media_id] = item
            
            # permalink ê¸°ì¤€ ì¸ë±ìŠ¤ ìƒì„±
            permalink = item.get("permalink")
            if permalink:
                shortcode = normalize_permalink(permalink)
                if shortcode and shortcode not in permalink_index:
                    # ì²« ë²ˆì§¸ ë°œê²¬ëœ í•­ëª©ë§Œ ì¸ë±ìŠ¤ì— ì €ì¥ (ì¤‘ë³µ ë°©ì§€)
                    permalink_index[shortcode] = item

    elif isinstance(raw_data, dict):
        for hashtag, entries in raw_data.items():
            storage: Dict[str, dict] = {}
            if isinstance(entries, dict):
                for media_id, media_data in entries.items():
                    if isinstance(media_data, dict):
                        storage[media_id] = media_data
                        # permalink ê¸°ì¤€ ì¸ë±ìŠ¤ ìƒì„±
                        permalink = media_data.get("permalink")
                        if permalink:
                            shortcode = normalize_permalink(permalink)
                            if shortcode and shortcode not in permalink_index:
                                permalink_index[shortcode] = media_data
            elif isinstance(entries, list):
                for media_data in entries:
                    if isinstance(media_data, dict):
                        media_id = media_data.get("id")
                        if media_id:
                            storage[media_id] = media_data
                            # permalink ê¸°ì¤€ ì¸ë±ìŠ¤ ìƒì„±
                            permalink = media_data.get("permalink")
                            if permalink:
                                shortcode = normalize_permalink(permalink)
                                if shortcode and shortcode not in permalink_index:
                                    permalink_index[shortcode] = media_data
            data[hashtag] = storage

    return data, permalink_index


def save_data(data: dict) -> None:
    DATA_FILE.parent.mkdir(parents=True, exist_ok=True)
    flattened: List[dict] = []
    for storage_hashtag, media_map in data.items():
        if not isinstance(media_map, dict):
            continue
        for media_id, media_item in media_map.items():
            if not isinstance(media_item, dict):
                continue
            entry = media_item.copy()
            entry["id"] = media_id
            # hashtag í•„ë“œëŠ” ì›ë³¸ ê°’ì„ ë³´ì¡´
            # ì›ë³¸ í•­ëª©ì— hashtag í•„ë“œê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ìœ ì§€
            # "unknown" ê·¸ë£¹ì— ìˆì§€ë§Œ ì›ë³¸ì— hashtagê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ìœ ì§€
            # "unknown" ê·¸ë£¹ì— ìˆê³  ì›ë³¸ì— hashtagê°€ ì—†ìœ¼ë©´ hashtag í•„ë“œë¥¼ ì¶”ê°€í•˜ì§€ ì•ŠìŒ
            original_hashtag = entry.get("hashtag")
            if storage_hashtag != "unknown":
                # ì •ìƒì ì¸ hashtag ê·¸ë£¹: storage_hashtag ì‚¬ìš©
                entry["hashtag"] = storage_hashtag
            elif original_hashtag:
                # "unknown" ê·¸ë£¹ì´ì§€ë§Œ ì›ë³¸ì— hashtagê°€ ìˆìœ¼ë©´ ì›ë³¸ ê°’ ìœ ì§€
                entry["hashtag"] = original_hashtag
            # else: "unknown" ê·¸ë£¹ì´ê³  ì›ë³¸ì— hashtagê°€ ì—†ìœ¼ë©´ hashtag í•„ë“œë¥¼ ì¶”ê°€í•˜ì§€ ì•ŠìŒ
            flattened.append(entry)

    with open(DATA_FILE, "w", encoding="utf-8") as file:
        json.dump(flattened, file, ensure_ascii=False, indent=2)


def verify_access_token() -> bool:
    """Access Token ìœ íš¨ì„± ê²€ì¦"""
    # ë°©ë²• 1: Facebook Graph APIë¡œ í† í° ê²€ì¦
    try:
        url = "https://graph.facebook.com/v18.0/me"
        params = {"access_token": ACCESS_TOKEN}
        response = requests.get(url, params=params).json()
        
        if "error" in response:
            error = response["error"]
            error_code = error.get("code")
            error_message = error.get("message", "")
            
            logging.error(f"âŒ Access Token ê²€ì¦ ì‹¤íŒ¨: {error}")
            
            if error_code in [190, 10]:
                logging.error("ğŸ”´ í† í°ì´ ë§Œë£Œë˜ì—ˆê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
                logging.error("ğŸ’¡ í•´ê²° ë°©ë²•: Facebook Developer Consoleì—ì„œ ìƒˆ Access Tokenì„ ë°œê¸‰ë°›ìœ¼ì„¸ìš”.")
                return False
            elif error_code == 200:
                logging.error("ğŸ”´ ê¶Œí•œì´ ë¶€ì¡±í•©ë‹ˆë‹¤!")
                logging.error("ğŸ’¡ í•´ê²° ë°©ë²•: Facebook Appì— í•„ìš”í•œ ê¶Œí•œì„ ì¶”ê°€í•˜ì„¸ìš”.")
                return False
            else:
                logging.warning(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬ ì½”ë“œ: {error_code}")
                return False
        
        logging.info(f"âœ… Access Token ê²€ì¦ ì„±ê³µ: {response.get('name', 'Unknown')} (ID: {response.get('id', 'Unknown')})")
        
        # ë°©ë²• 1-2: Access Tokenì˜ ê¶Œí•œ í™•ì¸
        try:
            debug_url = "https://graph.facebook.com/v18.0/debug_token"
            debug_params = {
                "input_token": ACCESS_TOKEN,
                "access_token": ACCESS_TOKEN
            }
            debug_response = requests.get(debug_url, params=debug_params).json()
            
            if "data" in debug_response:
                data = debug_response["data"]
                scopes = data.get("scopes", [])
                logging.info(f"ğŸ“‹ Access Token ê¶Œí•œ ëª©ë¡:")
                for scope in scopes:
                    logging.info(f"   - {scope}")
                
                # Instagram ê´€ë ¨ ê¶Œí•œ í™•ì¸
                instagram_scopes = [s for s in scopes if "instagram" in s.lower()]
                if instagram_scopes:
                    logging.info(f"âœ… Instagram ê´€ë ¨ ê¶Œí•œ í™•ì¸ë¨: {', '.join(instagram_scopes)}")
                else:
                    logging.warning(f"âš ï¸ Instagram ê´€ë ¨ ê¶Œí•œì´ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            logging.debug(f"ê¶Œí•œ í™•ì¸ ì¤‘ ì˜ˆì™¸ (ë¬´ì‹œ): {e}")
        
        # ë°©ë²• 2: Instagram Business Account ì ‘ê·¼ ê¶Œí•œ í™•ì¸
        if INSTAGRAM_BUSINESS_ID:
            try:
                ig_url = f"https://graph.facebook.com/v18.0/{INSTAGRAM_BUSINESS_ID}"
                ig_params = {
                    "fields": "id,username",
                    "access_token": ACCESS_TOKEN
                }
                ig_response = requests.get(ig_url, params=ig_params).json()
                
                if "error" in ig_response:
                    error = ig_response["error"]
                    error_code = error.get("code")
                    if error_code == 100:
                        # í•„ë“œ ê´€ë ¨ ì—ëŸ¬ëŠ” ë¬´ì‹œí•˜ê³  ê¸°ë³¸ ì •ë³´ë§Œ í™•ì¸
                        logging.warning(f"âš ï¸ ì¼ë¶€ í•„ë“œ ì ‘ê·¼ ì‹¤íŒ¨ (ë¬´ì‹œ): {error.get('message', '')}")
                        # í•„ë“œ ì—†ì´ ë‹¤ì‹œ ì‹œë„
                        ig_params = {
                            "fields": "id",
                            "access_token": ACCESS_TOKEN
                        }
                        ig_response = requests.get(ig_url, params=ig_params).json()
                        if "error" in ig_response:
                            logging.warning(f"âš ï¸ Instagram Business Account ì ‘ê·¼ í™•ì¸ ì‹¤íŒ¨: {ig_response['error']}")
                            logging.warning("ğŸ’¡ Instagram Business Account IDê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
                        else:
                            logging.info(f"âœ… Instagram Business Account í™•ì¸: ID {ig_response.get('id', 'Unknown')}")
                    else:
                        logging.warning(f"âš ï¸ Instagram Business Account ì ‘ê·¼ í™•ì¸ ì‹¤íŒ¨: {error}")
                        logging.warning("ğŸ’¡ Instagram Business Account IDê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
                else:
                    logging.info(f"âœ… Instagram Business Account í™•ì¸: {ig_response.get('username', 'Unknown')} (ID: {ig_response.get('id', 'Unknown')})")
            except Exception as e:
                logging.warning(f"âš ï¸ Instagram Business Account í™•ì¸ ì¤‘ ì˜ˆì™¸: {e}")
        
        return True
    except Exception as e:
        logging.error(f"âŒ Access Token ê²€ì¦ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        return False


def fetch_hashtag_id(hashtag: str) -> Optional[str]:
    url = "https://graph.facebook.com/v18.0/ig_hashtag_search"
    
    # í•´ì‹œíƒœê·¸ì—ì„œ # ì œê±° (APIëŠ” # ì—†ì´ë„ ê²€ìƒ‰ ê°€ëŠ¥í•˜ì§€ë§Œ, ì¼ê´€ì„±ì„ ìœ„í•´ ì œê±°)
    query_string = hashtag.lstrip('#')
    
    params = {
        "user_id": INSTAGRAM_BUSINESS_ID,
        "q": query_string,
        "access_token": ACCESS_TOKEN
    }
    
    # ë””ë²„ê¹…: ì‹¤ì œ ì „ì†¡ë˜ëŠ” URL í™•ì¸
    import urllib.parse
    full_url = f"{url}?{urllib.parse.urlencode(params)}"
    logging.debug(f"ğŸ” ìš”ì²­ URL: {full_url.replace(ACCESS_TOKEN, 'ACCESS_TOKEN_HIDDEN')}")
    logging.debug(f"ğŸ” í•´ì‹œíƒœê·¸ ì›ë³¸: {repr(hashtag)}, ì¿¼ë¦¬ ë¬¸ìì—´: {repr(query_string)}")
    
    response = requests.get(url, params=params).json()
    logging.info(f"í•´ì‹œíƒœê·¸ ê²€ìƒ‰ê²°ê³¼ ({hashtag}): {response}")

    if "error" in response:
        error = response["error"]
        error_code = error.get("code")
        error_subcode = error.get("error_subcode")
        
        # í† í° ê´€ë ¨ ì—ëŸ¬ ì½”ë“œ í™•ì¸
        if error_code in [190, 10]:
            logging.error(f"ğŸ”´ í† í°ì´ ë§Œë£Œë˜ì—ˆê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤! (í•´ì‹œíƒœê·¸: {hashtag})")
            logging.error(f"   ì—ëŸ¬: {error}")
            return None
        elif error_code == 200:
            logging.error(f"ğŸ”´ ê¶Œí•œì´ ë¶€ì¡±í•©ë‹ˆë‹¤! (í•´ì‹œíƒœê·¸: {hashtag})")
            logging.error(f"   ì—ëŸ¬: {error}")
            return None
        elif error_code == 24 and error_subcode == 2207024:
            # Code 24ëŠ” í•´ì‹œíƒœê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ëŠ” ì˜ë¯¸
            # Instagram Graph APIì˜ ì •ì±… ë³€ê²½ìœ¼ë¡œ í•´ì‹œíƒœê·¸ ê²€ìƒ‰ì´ ì œí•œë˜ì—ˆì„ ê°€ëŠ¥ì„±
            error_msg = error.get("error_user_msg", "").lower()
            if "ìœ íš¨í•˜ì§€ ì•Š" in error_msg or "invalid" in error_msg:
                logging.warning(f"âš ï¸ í•´ì‹œíƒœê·¸ ê²€ìƒ‰ ì‹¤íŒ¨ ({hashtag}): í† í° ë¬¸ì œ ê°€ëŠ¥ì„±")
            else:
                logging.warning(f"âš ï¸ í•´ì‹œíƒœê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {hashtag}")
                logging.warning(f"   ğŸ’¡ Instagram Graph APIì˜ ì •ì±… ë³€ê²½ìœ¼ë¡œ í•´ì‹œíƒœê·¸ ê²€ìƒ‰ì´ ì œí•œë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                logging.warning(f"   ğŸ’¡ ëŒ€ì•ˆ: Selenium í¬ë¡¤ë§ ì‚¬ìš© (instagram_crawling_userposts.py)")
        
        logging.error(f"í•´ì‹œíƒœê·¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({hashtag}): {error}")
        return None

    data = response.get("data", [])
    if not data:
        logging.warning(f"í•´ë‹¹ í•´ì‹œíƒœê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {hashtag}")
        return None

    hashtag_id = data[0].get("id")
    logging.info(f"í•´ì‹œíƒœê·¸ ID ({hashtag}): {hashtag_id}")
    return hashtag_id


def fetch_all_media(hashtag_id: str) -> List[dict]:
    media_url = f"https://graph.facebook.com/v24.0/{hashtag_id}/recent_media"
    params = {
        "user_id": INSTAGRAM_BUSINESS_ID,
        "fields": "id,caption,media_type,media_url,permalink,timestamp,like_count,comments_count",
        "access_token": ACCESS_TOKEN,
        "limit": 50
    }

    all_media = []
    next_url = media_url
    next_params = params

    while next_url:
        response = requests.get(next_url, params=next_params).json()
        if "error" in response:
            logging.error(f"ë¯¸ë””ì–´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {response['error']}")
            break

        media_data = response.get("data", [])
        all_media.extend(media_data)

        paging = response.get("paging", {})
        next_url = paging.get("next")
        next_params = None  # next URLì— ëª¨ë“  íŒŒë¼ë¯¸í„°ê°€ í¬í•¨ë˜ì–´ ìˆìŒ

        if not media_data:
            break

    return all_media


WHITESPACE_PATTERN = re.compile(r"\s+")
HASHTAG_PATTERN = re.compile(r"#([\w\d_]+)", re.UNICODE)


def clean_content(text: Optional[str]) -> str:
    if not text:
        return ""
    cleaned = text.replace("\u200b", " ").replace("\r", " ").replace("\n", " ")
    cleaned = WHITESPACE_PATTERN.sub(" ", cleaned).strip()
    return cleaned


def extract_hashtags(text: str) -> List[str]:
    return [f"#{tag}" for tag in HASHTAG_PATTERN.findall(text)]


def process_media_item(media_item: dict) -> dict:
    media_id = media_item.get("id")
    media_type = media_item.get("media_type")

    if media_type == "CAROUSEL_ALBUM":
        # ìºëŸ¬ì…€ í•˜ìœ„ ë¯¸ë””ì–´ëŠ” í•´ì‹œíƒœê·¸ ê²€ìƒ‰ ê²°ê³¼ë¡œëŠ” ì¡°íšŒí•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ëŒ€í‘œ URLë§Œ ì €ì¥
        media_urls = [media_item.get("media_url")] if media_item.get("media_url") else []
    else:
        media_url = media_item.get("media_url")
        media_urls = [media_url] if media_url else []

    content = clean_content(media_item.get("caption"))
    hashtags = extract_hashtags(content)
    content_count = len(content)
    hashtag_count = len(hashtags)

    processed = {
        "id": media_id,
        "media_type": media_type,
        "media_url": media_urls,
        "media_count": len(media_urls),
        "content": content,
        "hashtags": hashtags,
        "content_count": content_count,
        "hashtag_count": hashtag_count,
        "permalink": media_item.get("permalink"),
        "timestamp": media_item.get("timestamp"),
        "like_count": media_item.get("like_count"),
        "comments_count": media_item.get("comments_count")
    }

    return processed


hashtags = ["#ë…ì¼í”¼ì— ",
    "#í”¼ì— ì£¼ìŠ¤",
    "#ì•¡í‹°ë°”ì´ì¦ˆ",
    "#ë¦¬ìŠ¤í† ë ˆì´íŠ¸",
    "#í”¼íŠ¸ë¼ì¸",
    "#íŒŒì›Œì¹µí…Œì¼",
    "#íƒ‘ì‰ì´í”„",
    "#ë¶€ì‚°í”¼ì— ",
    "#ì—¬ì£¼í”¼ì— ",
    "#ê´‘ì£¼í”¼ì— ",
    "#ì„±ë‚¨í”¼ì— ",
    "#ì²œì•ˆí”¼ì— ",
    "#íŒŒì£¼í”¼ì— ",
    "#ëŒ€êµ¬í”¼ì— ",
    "#ê²½ì£¼í”¼ì— ",
    "#ê¹€í•´í”¼ì— ",
    "#ìˆ˜ì›í”¼ì— ",
    "#ì¸ì²œí”¼ì— ",
    "#ë‚¨ì–‘ì£¼í”¼ì— ",
    "#ê°•ì„œí”¼ì— ",
    "#ì˜ì •ë¶€í”¼ì— ",
    "#ì„œìš¸í”¼ì— ",
    "#í”¼ì— ì‚¬ì—…",
    "#í”¼íŠ¸ë¼ì¸ì•°ë²„ì„œë”",
    "#í”¼ì— ë‹¤ì´ì–´íŠ¸"]

# ë¡œê¹… ì´ˆê¸°í™”
setup_logging(str(BASE_DIR / "instagram.log"))

# Access Token ìœ íš¨ì„± ê²€ì¦
logging.info("=" * 70)
logging.info("ğŸ” Access Token ìœ íš¨ì„± ê²€ì¦ ì¤‘...")
logging.info("=" * 70)
if not verify_access_token():
    logging.error("=" * 70)
    logging.error("âŒ Access Tokenì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    logging.error("=" * 70)
    exit(1)
logging.info("=" * 70)
logging.info("")

existing_data, permalink_index = load_existing_data()
logging.info(f"ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {sum(len(media_map) for media_map in existing_data.values())}ê°œ í•­ëª©, {len(permalink_index)}ê°œ ê³ ìœ  permalink")


for hashtag in hashtags:
    hashtag_id = fetch_hashtag_id(hashtag)
    if not hashtag_id:
        continue

    media_items = fetch_all_media(hashtag_id)
    logging.info(f"ê°€ì ¸ì˜¨ ê²Œì‹œë¬¼ ìˆ˜ ({hashtag}): {len(media_items)}")

    hashtag_storage = existing_data.setdefault(hashtag, {})
    new_count = 0
    updated_count = 0
    duplicate_by_permalink_count = 0
    duplicate_by_media_id_count = 0

    for item in media_items:
        processed_item = process_media_item(item)
        media_id = processed_item.get("id")
        if not media_id:
            continue
        processed_item["hashtag"] = hashtag
        
        permalink = processed_item.get("permalink")
        shortcode = normalize_permalink(permalink) if permalink else None

        # 1. permalink ê¸°ì¤€ ì¤‘ë³µ ì²´í¬ (ìš°ì„ )
        duplicate_by_permalink = False
        if shortcode and shortcode in permalink_index:
            existing_item = permalink_index[shortcode]
            existing_hashtag = existing_item.get("hashtag")
            existing_media_id = existing_item.get("id")
            
            # ê°™ì€ permalinkê°€ ë‹¤ë¥¸ í•´ì‹œíƒœê·¸ì— ìˆìœ¼ë©´ ì¤‘ë³µ
            if existing_hashtag != hashtag:
                duplicate_by_permalink = True
                duplicate_by_permalink_count += 1
                logging.info(f"âš ï¸ ì¤‘ë³µ ë°œê²¬ (permalink ê¸°ì¤€) - {hashtag}: permalink={permalink}, shortcode={shortcode}, ê¸°ì¡´ í•´ì‹œíƒœê·¸={existing_hashtag}, ê¸°ì¡´ media_id={existing_media_id}, ìƒˆ media_id={media_id}")
                # ì¤‘ë³µì´ë¯€ë¡œ ìŠ¤í‚µ
                continue
            # ê°™ì€ í•´ì‹œíƒœê·¸ì— ê°™ì€ permalinkê°€ ìˆìœ¼ë©´ media_id ê¸°ì¤€ìœ¼ë¡œ ì²˜ë¦¬ (ì•„ë˜ ë¡œì§ìœ¼ë¡œ)
        
        # 2. media_id ê¸°ì¤€ ì¤‘ë³µ ì²´í¬
        stored_item = hashtag_storage.get(media_id)

        if stored_item:
            duplicate_by_media_id_count += 1
            logging.info(f"ğŸ”„ ì¤‘ë³µ ë°œê²¬ (media_id ê¸°ì¤€) - {hashtag}: media_id={media_id}, permalink={permalink}")
            
            # ê¸°ì¡´ ë°ì´í„°ì™€ ìƒˆ ë°ì´í„° ë³‘í•©
            # ë‹¨, media_url, media_count, media_caption, audio_captionì€ ê¸°ì¡´ ë°ì´í„° ë³´ì¡´
            merged_item = {**stored_item, **processed_item}
            
            # media_url ë³´ì¡´ ë¡œì§: ê¸°ì¡´ì— ìˆ˜ì§‘í•œ ì´ë¯¸ì§€ê°€ ë” ë§ìœ¼ë©´ ë³´ì¡´
            existing_media_urls = stored_item.get("media_url", [])
            new_media_urls = processed_item.get("media_url", [])
            
            if isinstance(existing_media_urls, list) and len(existing_media_urls) > 1:
                # ê¸°ì¡´ì— instagram_extract_imgurl.pyì—ì„œ ìˆ˜ì§‘í•œ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë³´ì¡´
                # ë‹¨, ìƒˆë¡œìš´ URLì´ ìˆê³  ê¸°ì¡´ì— ì—†ìœ¼ë©´ ì¶”ê°€
                existing_urls_set = set(existing_media_urls)
                for new_url in new_media_urls:
                    if new_url and new_url not in existing_urls_set:
                        existing_media_urls.append(new_url)
                merged_item["media_url"] = existing_media_urls
                merged_item["media_count"] = len(existing_media_urls)
            elif isinstance(new_media_urls, list) and len(new_media_urls) > 0:
                # ê¸°ì¡´ ë°ì´í„°ê°€ ì—†ê±°ë‚˜ 1ê°œ ì´í•˜ë©´ ìƒˆ ë°ì´í„° ì‚¬ìš©
                merged_item["media_url"] = new_media_urls
                merged_item["media_count"] = len(new_media_urls)
            
            # media_caption ë³´ì¡´ (instagram_extract_imgurl.pyì—ì„œ OCRë¡œ ìƒì„±í•œ ë°ì´í„°, ë¦¬ìŠ¤íŠ¸ í˜•ì‹)
            existing_media_caption = stored_item.get("media_caption", [])
            # ê¸°ì¡´ media_captionì´ ë¬¸ìì—´ì´ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (í•˜ìœ„ í˜¸í™˜ì„±)
            if isinstance(existing_media_caption, str):
                existing_media_caption = [line.strip() for line in existing_media_caption.split("\n") if line.strip()]
            elif not isinstance(existing_media_caption, list):
                existing_media_caption = []
            
            if existing_media_caption:
                merged_item["media_caption"] = existing_media_caption
            
            # audio_caption ë³´ì¡´ (instagram_extract_audio_from_json.pyì—ì„œ ì¶”ì¶œí•œ ì˜¤ë””ì˜¤ í…ìŠ¤íŠ¸)
            existing_audio_caption = stored_item.get("audio_caption")
            if existing_audio_caption:
                merged_item["audio_caption"] = existing_audio_caption
            
            # is_video ë³´ì¡´ (instagram_extract_audio_from_json.pyì—ì„œ ì„¤ì •í•œ ë¹„ë””ì˜¤ ì—¬ë¶€)
            existing_is_video = stored_item.get("is_video")
            if existing_is_video:
                merged_item["is_video"] = existing_is_video
            
            hashtag_storage[media_id] = merged_item
            # permalink ì¸ë±ìŠ¤ë„ ì—…ë°ì´íŠ¸
            if shortcode:
                permalink_index[shortcode] = merged_item
            updated_count += 1
        else:
            # ì‹ ê·œ í•­ëª©
            hashtag_storage[media_id] = processed_item
            # permalink ì¸ë±ìŠ¤ì— ì¶”ê°€
            if shortcode:
                permalink_index[shortcode] = processed_item
            new_count += 1
            logging.debug(f"âœ… ì‹ ê·œ í•­ëª© ì¶”ê°€ - {hashtag}: media_id={media_id}, permalink={permalink}")

    logging.info(f"ì²˜ë¦¬ ì™„ë£Œ ({hashtag}): ì‹ ê·œ={new_count}ê°œ, ì—…ë°ì´íŠ¸(media_id ì¤‘ë³µ)={updated_count}ê°œ, ìŠ¤í‚µ(permalink ì¤‘ë³µ)={duplicate_by_permalink_count}ê°œ")

save_data(existing_data)
total_posts = sum(len(media_map) for media_map in existing_data.values())
logging.info(f"ì´ {total_posts}ê°œ ê²Œì‹œë¬¼ì„ `{DATA_FILE}`ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")